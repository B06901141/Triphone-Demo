# Triphone FST Decode Result

| data                                                         | label                                                        | result                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| [DRL_Lecture_1_-_Policy_Gradient_(Review)-78](./dev/DRL_Lecture_1_-_Policy_Gradient_(Review)-78.wav) | 比如說 70% 會走 left，20% 走 right，10% 開火，等等           | 這個 其實 在 回頭 MAX 本身 這種 翻譯 是 存在 呢 開火 那 的 對應 的 那 |
| [DRL_Lecture_2_-__Proximal_Policy_Optimization_(PPO)-78](./dev/DRL_Lecture_2_-__Proximal_Policy_Optimization_(PPO)-78.wav) | sample data                                                  | SAMPLE DATA                                                  |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-78](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-78.wav) | 但是因為實際上，你當然不可能把所有的 state 通通都掃過        | 因為 實際上 你 當然 不 可能 把 所有 的 STATE 甚麼 山坡       |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-780](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-780.wav) | 那在每一個 episode，就你拿你的 agent                         | 每 一個 EPISODE TRAINING 那 你 的 AGENT                      |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-781](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-781.wav) | 你拿你的 actor 去跟環境做互動                                | 那 你 的 這個 ACTOR 去 跟 環境 做 不到                       |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-782](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-782.wav) | 那在每一次互動的過程中                                       | 那 每次 在 每 一次 互動 的 過程 中                           |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-783](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-783.wav) | 你都會得到一個 state st                                      | 你 都 會 得到 一個 STATE S T                                 |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-784](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-784.wav) | 一個遊戲的畫面                                               | 你 的 遊戲 的 畫面                                           |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-785](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-785.wav) | 那你會採取某一個 action at                                   | 那 你 會 採取 過的 ACTION 給你                               |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-786](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-786.wav) | 那怎麼知道採取那一個 action at 呢？你就根據你現在的 Q-function | 那 怎麼 知道 才能 ACTION EFFICIENT 的 機率 最大 的 FUNCTION  |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-787](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-787.wav) | 但是記得你要有 exploration 的機制                            | 那 設計 的 一樣 的 INFORMATION 幾次                          |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-788](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-788.wav) | 比如說你用 Boltzmann exploration 或是 Epsilon Greedy的 exploration | 你 要 做 出來 REGRESSION 跟 X 的 規律 的 INFORMATION         |
| [DRL_Lecture_3_-_Q-learning_(Basic_Idea)-789](./dev/DRL_Lecture_3_-_Q-learning_(Basic_Idea)-789.wav) | 也有一點 exploration 的機制                                  | 你 GRADIENT OPERATION 其實                                   |
| [DRL_Lecture_4_-_Q-learning_(Advanced_Tips)-78](./dev/DRL_Lecture_4_-_Q-learning_(Advanced_Tips)-78.wav) | 來當作你的 target value                                      | 來 當作 你 的 TARGET VALUE                                   |
| [DRL_Lecture_5_-_Q-learning_(Continuous_Action)-78](./dev/DRL_Lecture_5_-_Q-learning_(Continuous_Action)-78.wav) | 那當然這個不是一個 非常精確的做法                            | 那 在 這組 新 的 PATTERN 精確 的 做法                        |
| [DRL_Lecture_6_-_Actor-Critic-78](./dev/DRL_Lecture_6_-_Actor-Critic-78.wav) | 那今天假設我們可以 sample 足夠的次數                         | 那 今天 假設 我們 可以 SAMPLE 通過 的 次數                   |
| [DRL_Lecture_7_-_Sparse_Reward-78](./dev/DRL_Lecture_7_-_Sparse_Reward-78.wav) | 小孩當作一個 agent 的話                                      | 小孩 在 這個 REGION 的話                                     |
| [DRL_Lecture_8_-_Imitation_Learning-78](./dev/DRL_Lecture_8_-_Imitation_Learning-78.wav) | 人在 state s3  會採取 action  a3                             | 的 TASK 上 會 採取 ACTION A                                  |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-78](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-78.wav) | match key，看看這邊有沒有那個 key 出現                       | BATCH 你 有沒有 跟 你 出現                                   |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-780](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-780.wav) | 所以 f2(x) 他有 4 個片段                                     | 好 這 N 之間 呢 它 就 四個 簡短                              |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-781](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-781.wav) | 2^2，總共 4 個片段                                           | 這個 而是 反正 不是 的 平方                                  |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-782](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-782.wav) | 他是從 0 到 1/2（此處口誤，應為 1/4）                        | 它 是 考慮 到 特性                                           |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-783](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-783.wav) | 0 到 1/4，1/4 到 1/2，1/2 到 3/4，3/4 到 1                   | 只要 你 要 乘 根據 這個 需要 代表 代表 這個 這樣 子 的 你    |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-784](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-784.wav) | 總共四個片段                                                 | 是 更 簡單                                                   |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-785](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-785.wav) | 那你會發現說其實                                             | 那 你 的 方向 呢 其實                                        |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-786](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-786.wav) | f2(x) 其實跟 x^2 其實也滿接近的，所以                        | TESTING 的 跟 一直 到 X 也 蠻 近 誰 比較 接近 的             |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-787](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-787.wav) | 你有點看不清楚 f2(x) 在哪裡                                  | 它們 清楚 的 X 在 哪裡                                       |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-788](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-788.wav) | 哪如果你畫 f3(x) 的話                                        | 那 如果 你 轉換 X 在 的話                                    |
| [Deep_Learning_Theory_1-2_-_Potential_of_Deep-789](./dev/Deep_Learning_Theory_1-2_-_Potential_of_Deep-789.wav) | 他就有八個片段                                               | 它 就 改變 了                                                |
| [Deep_Learning_Theory_1-3_-_Is_Deep_better_than_Shallow-78](./dev/Deep_Learning_Theory_1-3_-_Is_Deep_better_than_Shallow-78.wav) | 看說，在給他這麼多的優勢的情況下                             | 然後 在 這個 給它 這麼 做 就是 的 結果                       |
| [Deep_Learning_Theory_2-2_-_Deep_Linear_Network-78](./dev/Deep_Learning_Theory_2-2_-_Deep_Linear_Network-78.wav) | 這樣講完以後，你覺得                                         | 好像 相關 以後 你 覺得 它                                    |
| [Deep_Learning_Theory_2-3_-_Does_Deep_Network_have_Local_Minima-78](./dev/Deep_Learning_Theory_2-3_-_Does_Deep_Network_have_Local_Minima-78.wav) | 他的 loss 一定都會增加，所以他是一個 local minima            | 它 的 LOSS 一定 會 這項 這 它 是 一個 LOCAL MINIMUM          |
| [Deep_Learning_Theory_2-4_-_Geometry_of_Loss_Surfaces_(Conjecture)-78](./dev/Deep_Learning_Theory_2-4_-_Geometry_of_Loss_Surfaces_(Conjecture)-78.wav) | 你只有一個 eigenvalue                                        | 你 只要 比較 大 的 VALUE                                     |
| [Deep_Learning_Theory_2-5_-_Geometry_of_Loss_Surfaces_(Empirical)-78](./dev/Deep_Learning_Theory_2-5_-_Geometry_of_Loss_Surfaces_(Empirical)-78.wav) | 但實際上有一個更低的地方是在這裡                             | 那 你 實際上 有 幾個 設定 的 地方 的 VECTOR                  |
| [GAN_Lecture_10_(2018)_-_Evaluation_&_Concluding_Remarks-78](./dev/GAN_Lecture_10_(2018)_-_Evaluation_&_Concluding_Remarks-78.wav) | 結果就會出現一些怪怪的結果怪怪的結果就是                     | 結果 就 會 出現 一些 怪怪的 結果 加 一個 怪怪的 結果 就是    |
| [GAN_Lecture_1_(2018)_-_Introduction-78](./dev/GAN_Lecture_1_(2018)_-_Introduction-78.wav) | 給你一個概念讓你知道這個技術運作起來大概是甚麼樣子           | 第一個 大概 在 知道 做 這個 技術 運作 起來 呢 大概 是 甚麼 樣子 |
| [GAN_Lecture_1_(2018)_-_Introduction-780](./dev/GAN_Lecture_1_(2018)_-_Introduction-780.wav) | 向左斜第二維就給他負的值，向右斜第二維就給他正的值等等       | 然後 再 做 寫 的 DATA 不 一樣 的 值 下 有些 呢 也 會 這邊 白色 的 值 |
| [GAN_Lecture_1_(2018)_-_Introduction-781](./dev/GAN_Lecture_1_(2018)_-_Introduction-781.wav) | 你可能會希望你 input 的 vector 他跟 output 東西的特徵還是有關係的 | 你 就 會 希望 你 INPUT 的 的 這個 VECTOR 它 OUTPUT 的 東西 的 特徵 還是 有 關係 的 |
| [GAN_Lecture_1_(2018)_-_Introduction-782](./dev/GAN_Lecture_1_(2018)_-_Introduction-782.wav) | 這件事情怎麼做到                                             | 那 這件 事情 怎麼 做到 呢                                    |
| [GAN_Lecture_1_(2018)_-_Introduction-783](./dev/GAN_Lecture_1_(2018)_-_Introduction-783.wav) | 怎麼樣產生這樣的 vector 呢還是有辦法的                       | 你 才 是 這樣 子 的 VECTOR 呢 還是 有 辦法 的                |
| [GAN_Lecture_1_(2018)_-_Introduction-784](./dev/GAN_Lecture_1_(2018)_-_Introduction-784.wav) | 可以 learn 一個 encoder，這個 encoder 是給他一張圖片，他把這個圖片的特徵用一個向量來表示 | 你 可以 LEARN 幾個 你 不能 這麼 做 的 是 給它 一張 圖片 來 它 整個 圖片 的 特徵 就是 下標 來 表示 |
| [GAN_Lecture_1_(2018)_-_Introduction-785](./dev/GAN_Lecture_1_(2018)_-_Introduction-785.wav) | 這個向量就是這邊的 code                                      | 那 這個 向量 就是 的點 的 CODE                               |
| [GAN_Lecture_1_(2018)_-_Introduction-786](./dev/GAN_Lecture_1_(2018)_-_Introduction-786.wav) | 給他一個圖片，他把這個圖片的特徵用向量來表示                 | 原來 圖片 讓 它 整個 圖片 的 特徵 一下 來 表示               |
| [GAN_Lecture_1_(2018)_-_Introduction-787](./dev/GAN_Lecture_1_(2018)_-_Introduction-787.wav) | 這個向量就是這邊的 code                                      | 這個 向量 就是 這邊 的 CODE                                  |
| [GAN_Lecture_1_(2018)_-_Introduction-788](./dev/GAN_Lecture_1_(2018)_-_Introduction-788.wav) | 怎麼 train 這樣一個 encoder 呢                               | 那 怎麼 TRAIN 這個 P CODE 呢                                 |
| [GAN_Lecture_1_(2018)_-_Introduction-789](./dev/GAN_Lecture_1_(2018)_-_Introduction-789.wav) | 記不記得在講 Machine Learning 的時候                         | 今天 我們 在講 MACHINE LEARNING 的 時候                      |
| [GAN_Lecture_2_(2018)_-_Conditional_Generation-78](./dev/GAN_Lecture_2_(2018)_-_Conditional_Generation-78.wav) | 你會發現說，今天 generator 在產生 image 的時候               | 你 會 發現 作 前面 GENERATOR 再 產生 IMAGE 的 時候           |
| [GAN_Lecture_3_(2018)_-_Unsupervised_Conditional_Generation-78](./dev/GAN_Lecture_3_(2018)_-_Unsupervised_Conditional_Generation-78.wav) | 然後它把人臉的特徵抽出來                                     | 然後 它 把 時間 點的 橙色 抽出來                             |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-78](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-78.wav) | 這件事情的意思就是說                                         | 這件 事情 其實 就 走                                         |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-780](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-780.wav) | 突然變很高的情形可能是不會發生的                             | 那 我們 今天 可能 就 會 發生 的                              |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-781](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-781.wav) | 因為 G0 跟 G1 是很像的所以這兩個 function 應該是比較接近     | 隨機 的 情況 之下 本身 這樣 一個 FUNCTION 你 應該 是 比較 接近 |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-782](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-782.wav) | 所以你可以只同樣用固定的 D0*                                 | 這個 例子 通通 加 一個 固定 的 地方                          |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-783](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-783.wav) | 就可以 evaluate G0 跟 G1 的 J-S Divergence                   | 就 可以 EVALUATE G 的 情況 的 TRANSFER                       |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-784](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-784.wav) | 所以在 train GAN 的時候                                      | 所以 今天 在 TRAIN 這個 GAN 的 時候                          |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-785](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-785.wav) | 它的 tip 就是因為你有這個假設                                | 它 的 就是 而 不會 有 非常 像 的                             |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-786](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-786.wav) | 就是 G0 跟 G1 應該是比較像的                                 | 根據 畫 你 應該 是 比較 小 的                                |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-787](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-787.wav) | 所以在 train generator 的時候                                | 所以 今天 在 TRAIN 你 的 GENERATOR 的 時候                   |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-788](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-788.wav) | 你就不能夠一次 update 太多                                   | 你 就 不 能夠 是 它 K 太 多                                  |
| [GAN_Lecture_4_(2018)_-_Basic_Theory-789](./dev/GAN_Lecture_4_(2018)_-_Basic_Theory-789.wav) | 但是在 train discriminator 的時候，理論上應該把它 train 到底 | 但是 在 TRAINING 的 DISTRIBUTION 一個 的 時候 理論 上 不該 把 它 TRAIN 好 |
| [GAN_Lecture_5_(2018)_-_General_Framework-78](./dev/GAN_Lecture_5_(2018)_-_General_Framework-78.wav) | 叫做 f *，就每一個 f 他都有一個對應的夥伴，叫做 f*           | 叫做 X 它 的 每 一個 X 它 對 有 幾個 最新 的 不 把 叫做 X BAR |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-78](./dev/GAN_Lecture_6_(2018)_-_WGAN                 | _EBGAN-78.wav)                                               |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-780](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-780.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-781](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-781.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-782](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-782.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-783](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-783.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-784](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-784.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-785](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-785.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-786](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-786.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-787](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-787.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-788](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-788.wav)                                              |
| [GAN_Lecture_6_(2018)_-_WGAN                                 | _EBGAN-789](./dev/GAN_Lecture_6_(2018)_-_WGAN                | _EBGAN-789.wav)                                              |
| [GAN_Lecture_7_(2018)_-_Info_GAN                             | _VAE-GAN                                                     | _BiGAN-78](./dev/GAN_Lecture_7_(2018)_-_Info_GAN             |
| [GAN_Lecture_8_(2018)_-_Photo_Editing-78](./dev/GAN_Lecture_8_(2018)_-_Photo_Editing-78.wav) | 這些是長髮的人臉                                             | 這些 是 相反 的 概念                                         |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-78](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-78.wav) | 但是如果從我們 training 的 criteria 來看                     | 但是 如果 它們 的 TRAINING 的 CRITERIA 來看                  |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-780](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-780.wav) | 你把裡面的參數做一下小小的變化                               | 你 把 裡面 的 參數 做 小小的 變化                            |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-781](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-781.wav) | 對 output 的影響是不確定的                                   | 對 OUTPUT 的 影響 是 不 確定 的                              |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-782](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-782.wav) | 因為中間有個 sampling 的 process                             | 你 會 裡面 從來 SAMPLING 的 PROCESS                          |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-783](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-783.wav) | 所以你每次得到的 output 是不一樣的                           | 這種 SEMI 每次 得到 OUTPUT 是 不 一樣 的                     |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-784](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-784.wav) | 你今天對你整個 network 做一個小小的變化的時候                | 你 今天 得到 的 理解 對 你 的 NETWORK 做 小小的 變化 的 時候 |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-785](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-785.wav) | 它對 output 的影響是不確定的                                 | 它 對 OUTPUT 的 影響 是 不 確定 的                           |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-786](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-786.wav) | 所以你根本就沒有辦法算微分出來                               | 這 根本 就 沒有 辦法 算 的 WEIGHT 規則 出來                  |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-787](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-787.wav) | 或者是另外一個更簡單的解釋就是，你回去用                     | 或者 是 另外 一個 一點 難解 釋 就是 你 會 需要               |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-788](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-788.wav) | TensorFlow 或 PyTorch implement 一下                         | CLASS 的 做 得 過去 IMPLEMENT 一下                           |
| [GAN_Lecture_9_(2018)_-_Sequence_Generation-789](./dev/GAN_Lecture_9_(2018)_-_Sequence_Generation-789.wav) | 看看如果 network 裡面有一個 sampling 的 process              | 如果 SAMPLING 的 PROCESS                                     |